# Agenda

- #17900: primop traits

- #17896: eta reduction based on Demand

- #17673: Eta-expansion, WW and NOINLINE, #17690: WW for coercions
  - Far future: Have one unified WW for eta expansion (based on `CoreArity`), coercions (no analysis info needed) and unboxing (Strictness/CPR)?

- #17676, !2525; and #5775, #3207: Consolidate when to apply IO hack

- Newtypes and ⊥ constraints: Is `⊥ ~ NT _` `Disjoint` or `PossiblyOverlap`ping? Probably the latter.
  - But we only ever add `x ~ ⊥` when checking for divergence, after which don't pass the resulting Delta on. Thus we never have to preserve it, because there is no way we would add `x /~ ⊥` *after* we added `x ~ ⊥`.
  - The other way round is very much possible, though. So we need to preserve `x /~ ⊥`. But for newtypes, satisfiability of that constraint depends on the field. so if we have `x ~ NT y`, `x /~ ⊥`, we might not detect that `y ~ ⊥` is impossible! #17725
  -  I think we should rather store the coercion in the `SharedIdEnv`
  - Problem: How to solve `x ~ y` when `r1 <| co1` represents `x` and `r2 <| co2` represents `y`?

- #915: Specialisation through type classes/defunctionalisation
  - #17592: Specialisation for call patterns is quite unreliable:
    ```hs
    f :: Maybe Bool -> Int -> Int
    f (Just True) 0 = 1
    f (Just True) n = f (Just True) (n-1)
    f _ 0 = 2
    f x n = f x (n-1)
    
    g x n = f (Just x) n
    h n = g True n
    ```
    There are situations in which `g` has not been inlined into `h` by the time SpecConstr runs. SpecConstr will then create two specialisations: One for `(Just True, _)` (`f1`) and one for `(Just _, _)` (`f2`), the former of which is a strict specialisation of the latter. The simplifier will then rewrite the call site in `g` to `f2`. Now, at some point `g` will be inlined and we see the call site `f2 True n`, which we *could* rewrite to `f1`. But all specialisation rules only apply to `f`, so we can't do the rewrite. The solution is simply to attach a derived specialisation rule to `f2`.
  - (Obsolete) Why not do specialisation of recursive functions instead of inlining them, as part of the simplifier? Consider separate pragma `{-# SPECIALISABLE #-}` or something
  - Pros:
    - No complicated and brittle reliance on rewrite rules
    - Like `INLINE`, the pragma is persisted throughout transformations
    - It seems like the logical way to do inlining for recursive functions
  - Cons:
    - Probably quirky for complicated recursion schemes
    - How does this work for rewriting recursive call sites? Seems impossible without RULEs and thus SpecConstr. OK, that won't work

- https://github.com/ghc-proposals/ghc-proposals/pull/43 Or patterns: Potential bachelor's thesis?
  - osa1 ultimately after a long and tedious discussion gave up.
  - Why? What's needed? A formal Specification? Which part? Static or dynamic semantics?
  - Also how much? Whole pattern language or just enough of a fragment to explain or patterns?
  - I see there is https://gitlab.haskell.org/rae/haskell as a starting point, but it seems to focus entirely on static semantics. But probably the document to complete?

- !2218 Unlifted data types

# Pattern-match checking

## Patches

Those with an MR actually have code.

- Clean up `provideEvidence`, define `ensureInhabited delta = null <$> provideEvidence 1 delta`
  - !1975 featured a rewrite, which makes for better warning messages
  - But `provideEvidence` currently assumes that every COMPLETE set is inhabited, and thus implicitly assumes that `ensureInhabited` is true for that data type. So we can't actually just re-define it in terms of the other just yet.
  - `provideEvidence` currently picks the smallest residual COMPLETE set for reports. But it doesn't consider type information! So it may indeed happen that we pick a residual COMPLETE set that looks smaller (say, size 2) and is still inhabited in favor of one that disregarding type info looks bigger (size 3) but actually only 1 is inhabited. For the same reason, we can't use `provideEvidence` as a replacement for `ensureInhabited`.
  - It *is* possible to make `provideEvidence` behave appropriately to replace `ensureInhabited`, but it's not very efficient. Also `ensureInhabited` is entirely orthogonal to what `provideEvidence` does. Think of recursive data types, for example: `provideEvidence` doesn't attempt to recurse *at all*. It just doesn't make for good warning messages.

- #17378, !1765: Preserve non-void constraints  
  - Should not remove inhabitation candidate stuff just yet, newtypes...
  - Perhpas postpone test until get to RHS (pmc []), and then ask for `not (null (provideEvidence 1 delta))`

- Implement "smarter `CoreMap`"
- Test for "N series" (Matching over a binary tree, like the code generated by `-XDeriveGeneric`)

## Issues

- #15532: Levity polymorphism and ANF  
  - We talked about it with Richard and came to the understanding that it would probably work, but entail refactorings of Core to Core passes which assume they can just let-bind everything.
  - Also we shouldn't worry about it until we need it. But it's a logical next step after we have unlifted datatypes, otherwise there is no chance of code re-use.

## Epics

- Think about how to fix "regression" in T11822  
  - SG bets a smart `CoreMap` would do
- Maybe pattern-match check typed TH quotations? SG doesn't think this is a good idea, because they might not even end up in that form in spliced code.
- Can we check if a clause is uniform? E.g. can be moved around (more or less) freely, up or down.  
  - I think we can, by trying to move up the clause and see if its new Covered set has a non-empty intersection (e.g. overlaps) with the clause that was previously there. Example:  
    ```haskell
    data T = A | B | C
    f (Just False) = ()
    f Nothing      = ()
    f (Just _)     = ()
    ```
    If we try to move the third clause up once, it covers the left over `Just True`. The second clause covers `Nothing`, so  the two clauses don't overlap. If we try to move up the third clause to the top, it suddenly covers `Just _`, which overlaps with `Just False` from the actual first clause. So we may switch second and third clause but not move the third clause to the top.
  - This is very similar to redundancy checking, but in redundancy checking we see if we *completely* overlap the pattern. Here, we see if their Covered sets overlap *at all* instead of seeing if one completely covers the other.
  - I suppose this also has tricky interactions with bottom. But our existing machinery should cover it.

# Nested CPR

- Mostly working prototype at https://gitlab.haskell.org/ghc/ghc/tree/wip/nested-cpr-2019

## Roadblocks 

- Nested CPR of DataCon wrappers needs to look at RHS of wrapper (think of `data T = T !(Int, Int)`) 
- Do nested CPR for KindReps/TypeReps/Modules? Horrendeous signatures in T7360 and T8274, but stats only improve overall
- T9291: unsafePtrEquality checks for STG CSE  
  - `bar x = (Right x, Right x)` gets CPR'd, `$wbar x = (# x, x #)` can't CSE at call site. Fixed testcase with `lazy`, but is that the right thing to do?
- integerConstantFolding: `CONSTANT_FOLDED` on `decodeDoubleInteger`, but gets WW'd because of nested `Int64`
  - We can't really just return the unboxed Int#, because that's platform dependent. BUT we could return Int64# instead
  - Alternatively, inline `decodeIntegerDouble` and recognise the PrimOp, seems like the much saner behavior?!

# On hold

- https://gitlab.haskell.org/ghc/ghc/tree/wip/ext-arity: Rebased Zach's implementation of the extensionality paper  
  - Wait for levity polymorphism and matchability polymorphism to work out

# Done

- !1427: Separate CPR
- !2192: Reflect tree structure of clauses and gaurds in the syntax we check.
- #17270: `Origin` annotations should be consistent about TH  
  - Faintly related: #14838, #14899. Should we warn about TH? Probably guard it behind a flag. Off by default? SG thinks so. This code is generated potentially in another library by a different user. Also compiler performance
- #17248, #17376, !1975: Get rid of the special case for `-XEmptyCase`. Fix handling of newtypes because of testsuite failures. Some ground work for proper non-void constraint handling.
- #17357: Fix strictness of pattern synonyms. We came to the agreement that it's not worth the trouble and most useful pattern synonyms are strict anyway.


