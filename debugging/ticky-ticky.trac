== Ticky-ticky quick start ==

Suppose you are doing peformance debugging on a new GHC Core-to-Core optimisation
pass.  You have a program `prog` that allocates a bit more with the
optimisation on than when it is off.  But ''why'' is it allocating
more?  Using full-bore profiling is too big a hammer, becuase it changes the way optimisation works.  Ticky-ticky is just the thing.

Here is what I do:

 * Two build trees, one for the compiler (and libraries, etc) without the change, one for the compiler with the change

 * In both build trees, add `GhcLibHcOpts += -ticky`.  That makes the libraries generate ticky-ticky information.

 * Run `nofib` in both trees.  Use `nofib-analyse` to compare.

 * Find one where the allocation changes in the wrong direction, say `x2n1`.  (Allocation is a reasonable proxy for execution time, and has the huge merit of being repeatable and measurable at a fine grain.)

 * Compile `x2n1` in both trees with `-ticky`, and also generating Core and STG, thus:
{{{
$ cd x2n1
$ make clean
$ make boot
$ make EXTRA_HC_OPTS="-ticky -ddump-simpl -ddump-stg" >& x2n1.dump }}}
}}}

 * Run `x2n1` in both trees, with `+RTS -rx2n1.ticky` to dump ticky output into that file
{{{ 
$ x2n1 +RTS -rx2n1.ticky
}}}
 Some `nofib` programs need command-line arguments to run; look in `Makefile` to see.  Others require input on stdin; look for `*.stdin`.

 * Compare the two ticky files.  They each have a section looking like this
{{{
    Entries      Alloc    Alloc'd  Non-void Arguments      STG Name
--------------------------------------------------------------------------------
         92       2448          0   1 i                    unpack{v s72} (ghc-prim:GHC.CString) in 0k
         16       1112          0  11 +++.LEEMSMM          base:GHC.IO.Handle.Internals.mkDuplexHandle5{v r6vW}
          6        432          0  12 pMEiiipMEiii         base:GHC.IO.Encoding.UTF8.$wa{v r44d}
         10        400          0   4 LM>p                 base:GHC.IO.Handle.Internals.$wa2{v r6w5}
         22        352          0   1 L                    base:GHC.IO.Encoding.getFileSystemEncoding_go{v r2BF}
         19        336          0   2 LL                   base:GHC.Base.++{v 03}
}}}
 The column to focus on initially is `Alloc`, which gives the bytes allocated by the code fragment named under `STG Name`.  I generally sort both files by the `Alloc` column (using Unix command `sort -k2 -nr` on that region).

 * If your change is small, the two tables will look pretty similar, so you can just run your eye down until you find a difference.  Then go look in `x2n1.dump` for the unique (e.g `r6vW`) in the `STG Name`.  Look initially in the `STG Syntax` dump, but having found the right place I generally back up to the `Tidy Core` section which is far more readable.

 * Now you can compare the two secitons of Core code.

The good thing is that ticky-ticky is guaranteed to be non-invasive. It generates a bit of extra memory traffic for the instrumentation, but that's all.
