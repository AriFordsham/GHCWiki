== Done so far ==

* Original paper: [https://www.microsoft.com/en-us/research/publication/sequent-calculus-as-a-compiler-intermediate-language/ Sequent calculus as an intermediate language]

* Repo:  `git://github.com/lukemaurer/ghc`, branch `wip/join-points`

* New variant of Core.
  * IdDetails has a constructor for JoinPointId, with its arity.
  * Join points can be recursive
  * Lint checks many invariants about join points
  * All transformations are "join-point aware"; that is, they maintain join-point-hood.
  * Nullary join points do not take a void argument (as they did before).
  * Join-point Ids survive in Iface unfoldings

== Join Point Analysis (JPA) ==

Join Point Analysis (JPA), implemented in `CoreJoins.findJoinsInPgm`, is a new analysis that identifies join points, and marks them as such.

Currently we run JPA fairly frequently in the pipeline.  In due course this could become part of the occurrence analyser, because (a) we'd discover join points quickly, (b) it's doing much the same kind of thing (analysing occurrences).

Currently JPA has two passes, so that it can propagate the binding sites to occurrences.  Not necessary to do this if the simplifier runs immediately afterwards (it propagates).


== Transformations ==

These places need to be made join-point aware

* Worker/wrapper for strictness: we do want w/w for arguments, but not for the return side (CPR).

  We can't do CPR because (in the recursive case) the worker calls the wrapper, so it needs to be a join point, but a CPR wrapper always invokes the worker from a `case` expression, so it can't be a join point. Fortunately, CPR is rarely necessary for join points because they benefit from the CPR on their context:
{{{
  f z = let join j x y = (x+1, y+1)
        in case z of A -> j 1 2
                     B -> j 2 3
}}}
  Performing CPR on `f` gives us
{{{
    f z = case $wf z of (# a, b #) -> (a, b)
  $wf z = case (let join j x y = (x+1, y+1)
                in case z of A -> j 1 2
                             B -> j 2 3) of (a, b) -> (# a, b #)
}}}
  and now the simplifier will push the outer `case` into the join point:
{{{
  f z = case $wf z of (# a, b #) -> (a, b)
  $wf z = let join j x y = (# x+1, y+1 #)
          in case z of A -> j 1 2
                       B -> j 2 3
}}}
  (But what if the join point has the CPR property but the outer function doesn't? Seems like we're still ahead because original GHC would've ruined the join point.)

* Float In is crucial for finding join points, especially recursive ones. Consider:
{{{
f1 x = let j y = ... j z ... in
       case j x of A -> ...
                   B -> ...
}}}
  If neither branch mentions `j`, then `j` ''could'' be a join point if we moved it inward a bit:
{{{
f2 x = case (let join j y = ... j z ... in
             j x) of A -> ...
                     B -> ...
}}}
  Now the call to `j z` is in tail position with respect to `j`'s definition, so `j` can be a join point. However, the existing Float In pass goes a bit too far:
{{{
f3 x = case (let j y = ... j z ... in
             j) x of A -> ...
                     B -> ...
}}}
  This is ''equivalent'' to the second version, but it doesn't follow the join point invariant.
  
  This is a funny habit of the Float In implementation: it often floats a `let`-bound function inward so far that the body of the `let` becomes just the identifier itself. Normally the simplifier fixes this right up, so it hasn't ever mattered, but the simplifier will just move the `let` all the way out again, turning `f3` back into `f1`. We need Float In to get it exactly right, since handling `case`-of-recursive-join is exactly what lets us do fusion with recursion.

* Float-out.
  * First approximation: don't float join points at all.
  * Nullary join points, if floated, cease to be join points but instead become shared thunks.  On balance this is a win.
  * Floating to top level.  Doesn't make much difference either way.  BUT we lose the ability to move case context into the join point. eg
{{{
f x = let j y = blah in
      case x of
        True  -> j 1
        False -> j 2
}}}
  Now if we inline `f` into a case scrutinee, the case will move into `blah`.  BUT if we float `j` to top level.  So you might think that floating to top level was harmful. But consider (non-recursive case):
    * If `blah` is big, `f` will not inline, so we will never wrap its RHS in a case.
    * If `blah` is small enough for `f` to inline, then a fortiori `j` will inline too.
    Moreover, floating to top level makes f more likely to inline.  Example:
{{{
f x y = let j v = blah(strict in v) in
        case x of
          A -> j y
          B -> j y
          C -> x
}}}
    Here `f` is strict in `x` but not `y`.  If we float the joint point to top level, `f` can inline, which exposes the strictness in `y`.

    If `j` is recursive, the above argument doesn't apply; not floating a small join point would be good, so that f can inline with it intact.

* Simplifier, obviously.  Moving the context into the RHS of join points.  Never float a join point at all.


* Rule matcher does some let-floating of its own.
{{{
RULE   f (g x) = x+1

     ...(f (let v = e in g (v-2)))....
==> (rule fires)
     ...(let v = e in
         let x = v-2 in
         x+1)...
}}}
  Be careful not to do this for join points, since you can't float a join point out of an argument.

* NB: Float-in is a transformation that often creates join points:
{{{
     let f x = ...f x'... in
     case f t of alts
==>
     case (let f x = ...f x'... in f t) of alts
          -- Now f is a join point!
}}}
  NB: the very next run of the simplifier will float that `let`-binding for `f` out of the `case` scrutinee.  So it's important to look for join points before running the simplifier again.  Thus: (float-in; then find-join-points; then simplify)

* Added Late Lambda Lift.  But still work to do here.

== Cases where we win ==

Add `testsuite/test/perf/join-points/`

* For each place where you had to work to retain join points, make an example in which GHC currently destroys one, and behaves badly as a result.  Plus some examples like Section 4.3 in the paper.

* The original Float Out is quite hazardous to join points. Since a join point is never allocated as a closure, floating it out doesn't improve sharing, and in most cases it can't be a join point anymore, so floating only ''increases'' allocations. (As always, there may be second-order effects, however; for instance, floating outward may leave behind a function that's small enough to inline.)
{{{
f x =
  let g y =
    let <join> j z = ... x ...
    in case p y of A -> j 1
                   B -> j 2
  
  in ...
  
  =>

f x =
  let j z = ... x ... -- ruined!
      g y = case p y of A -> j 1
                        B -> j 2
  in ...
}}}

  We do still want to float out join points, however, just not too far. A good example occurs during unfold/destroy fusion, where a chain of filters becomes a series of trivially nested "loops":
{{{
filter odd . filter (> 4)

  =>

\xs ->
  let next xs0 =
    let <join> go1 xs1 =
      let <join> go2 xs2 =
        case xs2 of []    -> []
                    x:xs' -> case x > 4 of False -> go2 xs'
                                           True  -> case odd x of False -> go1 xs'
                                                                  True  -> x : next xs'
      in go2 xs1
    in go1 xs0
  in next xs
}}}
  Here we consider two filters, but this works to arbitrary depth. Since `go1` does nothing but invoke `go2`, it is just a needless bit of indirection. Float Out de-nests the loops:
{{{
\xs ->
  let next xs0 =
    let <join>
      go1 xs1 = go2 xs2
      go2 xs2 =
        case xs2 of []    -> []
                    x:xs' -> case x > 4 of False -> go2 xs'
                                           True  -> case odd x of False -> go1 xs'
                                                                  True  -> x : next xs'
    in go1 xs0
  in next xs
}}}
  And now `go1` can be inlined, completing the flattening process.

* Great fusion examples!  NB: that `go` functions do not start life as join points;
{{{
sfilter p (Stream s step)
  = Stream s fstep
  where
    fstep s = case step s of Done                   -> Done
                             Yield x s' | p x       -> Yield x s'
                                        | otherwise -> fstep s'
}}}
   Here `fstep` is not a join point, because it is not called in a saturated way.   But when we inline it, it becomes one.  We must spot this pronto before we destroy it.  (A reason for doing JPA in the occurrence analyser.)


== Still to do ==

* Try not propagating join points to occurrences in `findJoinsInPgm`; instead rely on simplifier.

* Desguarer should not add Void args to nullary join points.

* Dump the CoreToStg join point analysis in favour of the known join-points.
  * Check: does the CoreToStg analysis miss any JoinPointIds
  * Question: since STG is untyped, could it find more joint points that JPA does?)

* Currently CorePrep adds a void arg for a nullary join point.  Check: why?  What goes wrong if we don't do this?

* Idea: heap check for join point done at call site, not in join point itself. (Does not work for recursive join oints.)

* `CoreUnfold.sizeExpr`: SPJ claims: we should charge nothing for a join point binding or for its lambdas, or for its call.  (Reason: a join-point binding generates no allocation.)  Luke thinks that this was catastrophic in at least one case.  Investigate.

* Do Late Lambda Lifting (followed by simplify) ''after'' `CoreTidy`.
  * Then post LLL unfoldings won't affect downstream modules
  * But newly-small functions can still be inlined
  * Absolutely requires Arity/CAF info to be fed back from `CoreToStg`

* Join points are always fully eta-expanded, even when they would be trivial otherwise. This greatly simplifies many traversals, since typically the first step in processing a join point of arity N is to grab exactly N lambdas. The problem is that `exprIsTrivial` then returns `False`. This is particularly bad in `preInlineUnconditionally`, so there we check if a join point is eta-reducible to a trivial expression. But it's an ugly workaround, and there are other issues as well (sometimes trivial join points become loop breakers, for instance). Better would be to relax the invariant to allow trivial join points to elide lambdas, then provide a convenience function to eta-expand when needed (not hard to do for a trivial expression!).